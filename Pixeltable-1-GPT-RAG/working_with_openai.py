# -*- coding: utf-8 -*-
"""working-with-openai.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/pixeltable/pixeltable/blob/master/docs/release/tutorials/working-with-openai.ipynb

[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/pixeltable/pixeltable/blob/master/docs/release/tutorials/working-with-openai.ipynb)&nbsp;&nbsp;
[![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pixeltable/pixeltable/blob/master/docs/release/tutorials/working-with-openai.ipynb)

# Working with OpenAI in Pixeltable

Pixeltable unifies data and computation into a table interface. In the [Pixeltable Basics](https://pixeltable.github.io/pixeltable/tutorials/pixeltable-basics/) tutorial, we saw how OpenAI API calls can be incorporated into Pixeltable workflows. In this tutorial, we'll go into more depth on OpenAI integration. You'll need an OpenAI API key to run this demo.

### Prerequisites
- An OpenAI account with an API key (https://openai.com/index/openai-api/)

### Important Notes

- OpenAI usage may incur costs based on your OpenAI plan.
- Be mindful of sensitive data and consider security measures when integrating with external services.
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install -q pixeltable openai tiktoken sentence-transformers

from pixeltable.iterators.document import DocumentSplitter
from pixeltable.functions.huggingface import sentence_transformer
import pixeltable as pxt
import numpy as np
import urllib.request
import tiktoken

# Make sure we start with a clean slate
pxt.drop_table('rag_demo1.chunks', ignore_errors=True)
pxt.drop_table('rag_demo1.documents', ignore_errors=True)
pxt.drop_table('rag_demo1.queries', ignore_errors=True, force=True)
pxt.drop_table('rag_demo1.docs', ignore_errors=True)

"""## Creating the Table

First, we'll create a table and populate it with some sample data.
"""

# Create the Pixeltable workspace
pxt.create_dir('rag_demo1', ignore_errors=True)

# pxt.drop_table('demo.openai', ignore_errors=True)
# t = pxt.create_table('demo.openai', {'id': pxt.IntType(), 'input': pxt.StringType()})
pxt.drop_table('rag_demo1.docs', ignore_errors=True)
docs = pxt.create_table('rag_demo1.docs', {
    'source_doc': pxt.DocumentType()
})

import pixeltable as pxt
import urllib

# Local file path of the single PDF file
file_path = r"/content/data.pdf"

# Create a table to store the document
documents_t = pxt.create_table(
    'rag_demo1.documents', {'document': pxt.DocumentType()}
)

# Insert the single PDF document into the table
try:
    documents_t.insert([{'document': file_path}])
    print("Document inserted successfully.")
except pxt.exceptions.Error as e:
    print(f"Error inserting document: {e}")

# Create a view to split documents into chunks
chunks_t = pxt.create_view(
    'rag_demo1.chunks',
    documents_t,
    iterator=DocumentSplitter.create(
        document=documents_t.document,
        separators='token_limit', limit=300
    )
)

@pxt.expr_udf
def e5_embed(text: str) -> np.ndarray:
    return sentence_transformer(text, model_id='intfloat/e5-large-v2')

chunks_t.add_embedding_index('text', text_embed=e5_embed)

# chunks_t['new'] =sentence_transformer(chunks_t.text, model_id='paraphrase-MiniLM-L6-v2')

chunks_t.head(1)

query_text = "What is Chain of Thought?"

sim = chunks_t.text.similarity(query_text)
nvidia_eps_query = (
            chunks_t.order_by(sim, asc=False)
            .select(similarity=sim, text=chunks_t.text)
            .limit(5)
        )
print(nvidia_eps_query.collect())

"""<h1>Above My Work"""